{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3297c7d",
   "metadata": {},
   "source": [
    "<font size=6 color='blue'>\n",
    "\n",
    "<center> Clase 5, octubre 20 del 2021</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee5147",
   "metadata": {},
   "source": [
    "<font size=4 color='blue'>\n",
    "    \n",
    "## Problema a resolver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88436fb5",
   "metadata": {},
   "source": [
    "<img src=\"./images/Problema.jpg\" width=420 height=420 align = \"center\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c1d266",
   "metadata": {},
   "source": [
    "<font size=6 color='blue'>\n",
    "Mortalidad por diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a929b87",
   "metadata": {},
   "source": [
    "<img src=\"./images/Diabetes.png\" width=420 height=420 align = \"center\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6767a05",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Información sobre el problema a resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5e734e",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Evolución de la enfermedad de pacientes con Diabetes Mellitus despues de un año.\n",
    "    \n",
    "En el presente trabajo, la diabetes la caracterizamos con los siguientes diez rasgos: edad, sexo, índice de masa corporal, presión arterial promedio y seis mediciones de suero sanguíneo:\n",
    "\n",
    "     Colesterol Total \n",
    "     Baja densidad de liporoteinas\n",
    "     Alta densidad de lipoproteinas\n",
    "     Triglicéridos\n",
    "     Concentración de Lamorigina\n",
    "     Glucosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f1b5cb",
   "metadata": {},
   "source": [
    "<font size=4 color='blue'>\n",
    "    \n",
    "## Cuantificación de esta información"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7152877",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Se tienen información de 442 pacientes (m = 442). La respuesta de interés, Y, es una medida cuantitativa de la progresión de la enfermedad un año después del inicio del estudio. Los valores de Y varían entre 25 y 346\n",
    "\n",
    "Fuente de la información: [diabetes data](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html)    Artículo original: [Least-Angle-Regression_2004](./Literatura/Least-Angle-Regression_2004.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f7c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f71a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los datos se encuentran el el archivo diabetes.csv\n",
    "\n",
    "df = pd.read_csv('diabetes.csv', sep ='\\t')\n",
    "\n",
    "# se crea el dataframe df, el cual contiene los 10 rasgos relevantes de los pacientes\n",
    "# diabeticos, así como el progreso (y) de la enfermedad un año después de comenzado el estudio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13a6d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se despliegan las primeras 5 muestras (rasgos, objetivo)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7233d1",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "Las abreviaciones tienen el siguiente significado:\n",
    "    \n",
    "    AGE = Age\n",
    "    SEX = Sex\n",
    "    BMI = Body Mass Index (BMI)\n",
    "     BP = Mean Arterial Pressure (MAP)\n",
    "     S1 = Total Cholesterol (TC)\n",
    "     S2 = Low Density lipoproteins (LDL)\n",
    "     S3 = High Density lipoproteins (HDL)\n",
    "     S4 = Triglyceride (TG, TCH)\n",
    "     S5 = Serum Concentration of Lamorigine (LTG)\n",
    "     S6 = Glucose (GLU)\n",
    "     Y = Quantitative Measure of Diabetes Mellitus Disease Progression (QMDMDP) one year after the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64d8f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# el método describe() genera una tabla con informacion estadistica de cada uno de los rasgos y del objetivo.\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5637b7f4",
   "metadata": {},
   "source": [
    "## Se crean los histogramas para cada uno de los rasgos que caracteriza a los pacientes con diabetes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f870014",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,4,1)\n",
    "ax2 = plt.subplot(2,4,2)\n",
    "ax3 = plt.subplot(2,4,3)\n",
    "ax4 = plt.subplot(2,4,4)\n",
    "\n",
    "ax1.hist(df.AGE, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('Age (years)', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df.SEX, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('Sex', size=15)\n",
    "\n",
    "ax3.hist(df.BMI, bins=30, color='red',edgecolor='purple', alpha=0.5)\n",
    "ax3.set_xlabel('Body_mass_index', size=15)\n",
    "\n",
    "ax4.hist(df.BP, bins=30, color='blue',edgecolor='purple', alpha=0.5)\n",
    "ax4.set_xlabel('Mean_Arterial_Pressure', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c42044",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,4,1)\n",
    "ax2 = plt.subplot(2,4,2)\n",
    "ax3 = plt.subplot(2,4,3)\n",
    "ax4 = plt.subplot(2,4,4)\n",
    "\n",
    "ax1.hist(df.S1, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('Total Cholesterol', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df.S2, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('Low Density lipoproteins', size=15)\n",
    "\n",
    "ax3.hist(df.S3, bins=30, color='red',edgecolor='purple', alpha=0.5)\n",
    "ax3.set_xlabel('High Density lipoproteins', size=15)\n",
    "\n",
    "ax4.hist(df.S4, bins=30, color='blue',edgecolor='purple', alpha=0.5)\n",
    "ax4.set_xlabel('Triglyceride', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,3,1)\n",
    "ax2 = plt.subplot(2,3,2)\n",
    "ax3 = plt.subplot(2,3,3)\n",
    "\n",
    "ax1.hist(df.S5, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('Serum Concentration of Lamorigine', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df.S6, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('Glucose', size=15)\n",
    "\n",
    "ax3.hist(df.Y, bins=30, color='purple',edgecolor='black', alpha=0.5)\n",
    "ax3.set_xlabel('Y(Diabetes Mellitus Disease Progression)', size=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b5330",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Para quitar cualquier posible correlación entre las muestras (los renglones del DataFrame), estos se reordenan al azar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da49293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28cbc92",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "División de las muestras para aprender y para hacer predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb65664c",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "Se dividen la muestras originales en 2 conjuntos: 90 % para el entrenamiento y 10 % para hacer inferencias (predicciones) con el sistema de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e089bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.1\n",
    "\n",
    "train_ratio = int((1.0-test_ratio)*len(df.values[:,:]))\n",
    "\n",
    "df_train = df.iloc[0:train_ratio,:]\n",
    "df_test  = df.iloc[train_ratio:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d55687",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40178b92",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "\n",
    "Para trabajar con los modelos de aprendizaje,es adecuado que todas las variables tengan el mismo orden de magnitud. Por ello, se normalizan sus valores en las muestras que se emplearán en el entrenamiento, tanto los rasgos (X) y las variables objetivo (Y):\n",
    "\n",
    "$$x_{i,norm} = \\dfrac{x_{i}-\\mu}{\\sigma}$$\n",
    "    \n",
    "$$y_{i,norm} = \\dfrac{y_{i}-\\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_norm = (df_train - df_train.mean()) / df_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ee067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_norm = (df_test - df_train.mean()) / df_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2108a",
   "metadata": {},
   "source": [
    "<font size=4>\n",
    "    \n",
    "Histogramas de las variables que se emplearán en el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d00149",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,4,1)\n",
    "ax2 = plt.subplot(2,4,2)\n",
    "ax3 = plt.subplot(2,4,3)\n",
    "ax4 = plt.subplot(2,4,4)\n",
    "\n",
    "ax1.hist(df_train_norm.AGE, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('x1(Age)', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df_train_norm.SEX, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('x2(Sex)', size=15)\n",
    "\n",
    "ax3.hist(df_train_norm.BMI, bins=30, color='red',edgecolor='purple', alpha=0.5)\n",
    "ax3.set_xlabel('x3(Body_mass_index)', size=15)\n",
    "\n",
    "ax4.hist(df_train_norm.BP, bins=30, color='blue',edgecolor='purple', alpha=0.5)\n",
    "ax4.set_xlabel('x4(Mean_Arterial_Pressure)', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,4,1)\n",
    "ax2 = plt.subplot(2,4,2)\n",
    "ax3 = plt.subplot(2,4,3)\n",
    "ax4 = plt.subplot(2,4,4)\n",
    "\n",
    "ax1.hist(df_train_norm.S1, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('x5(Total Cholesterol)', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df_train_norm.S2, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('x6(Low Density lipoproteins)', size=15)\n",
    "\n",
    "ax3.hist(df_train_norm.S3, bins=30, color='red',edgecolor='purple', alpha=0.5)\n",
    "ax3.set_xlabel('x7(High Density lipoproteins)', size=15)\n",
    "\n",
    "ax4.hist(df_train_norm.S4, bins=30, color='blue',edgecolor='purple', alpha=0.5)\n",
    "ax4.set_xlabel('x8(Triglyceride)', size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8071d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8)) \n",
    "\n",
    "ax1 = plt.subplot(2,3,1)\n",
    "ax2 = plt.subplot(2,3,2)\n",
    "ax3 = plt.subplot(2,3,3)\n",
    "\n",
    "ax1.hist(df_train_norm.S5, bins=30, color='green',edgecolor='purple', alpha=0.5)\n",
    "ax1.set_xlabel('x9(Serum Concentration of Lamorigine)', size=15)\n",
    "ax1.set_ylabel('Frequency', size=15)\n",
    "\n",
    "ax2.hist(df_train_norm.S6, bins=30, color='orange',edgecolor='purple', alpha=0.5)\n",
    "ax2.set_xlabel('x10(Glucose)', size=15)\n",
    "\n",
    "ax3.hist(df_train_norm.Y, bins=30, color='purple',edgecolor='black', alpha=0.5)\n",
    "ax3.set_xlabel('Y(Diabetes Mellitus Disease Progression)', size=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dd1731",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df_train_norm.values[:,:-1]\n",
    "train_y = df_train_norm.values[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d7a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = df_test_norm.values[:,:-1]\n",
    "test_y = df_test_norm.values[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a29cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060975d0",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "# <center> Artificial Neural Networks </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4397ec",
   "metadata": {},
   "source": [
    "<font size=4 color='blue'>\n",
    "\n",
    "# <center> Implemented using the framework Pytorch </center>\n",
    "\n",
    "\n",
    "<font size=4 color='mediumvioletred'>\n",
    "   \n",
    "[Pytorch](https://pytorch.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6a51eb",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "    CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a66782",
   "metadata": {},
   "source": [
    "`conda install pytorch torchvision torchaudio cpuonly -c pytorch`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a95a276",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "    GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdcb389",
   "metadata": {},
   "source": [
    "`conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088db7af",
   "metadata": {},
   "source": [
    "<font size=5, color=brown>\n",
    "    Asiri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a7bf5",
   "metadata": {},
   "source": [
    "Asiri es un módulo en Python usando Pytorch, cuya finalidad es que los estudiantes se famliaricen con la manera en que se les presentarán los notebooks en Keras, y no tengan problemas en adaptar cualquiera de los frameworks en sus proyectos   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fb9a84",
   "metadata": {},
   "source": [
    "<font size=6, color=green>\n",
    "    Importación de paqueterías necesarias para trabajar con Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c203ff1",
   "metadata": {},
   "source": [
    "`sudo apt-get install graphviz`\n",
    "\n",
    "`pip install pytorch-model-summary`\n",
    "\n",
    "`conda install -c conda-forge scikit-learn`\n",
    "\n",
    "`conda install -c anaconda networkx`\n",
    "\n",
    "`conda install -c anaconda pandas`\n",
    "\n",
    "`conda install -c lightsource2-tag collection`\n",
    "\n",
    "`pip install torchviz`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111dbfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################Librerías de Pytorch###############################################\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "##########################Liberías complementarias###########################################\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "import json\n",
    "import itertools\n",
    "from itertools import product\n",
    "from IPython import display\n",
    "import pytorch_model_summary as pms\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import networkx as nx\n",
    "from torchviz import make_dot\n",
    "from itertools import chain\n",
    "##############################################################################################\n",
    "\n",
    "###########################Módulo creado para la clase########################################\n",
    "import asiri as ai\n",
    "##############################################################################################\n",
    "\n",
    "###########################Configuraciones complementarias ###################################\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True) #por default, ya viene con True, pero para asegurar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d86e61",
   "metadata": {},
   "source": [
    "<font size=5, color=red>\n",
    "    Reproducibilidad en Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9fe224",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f164232b",
   "metadata": {},
   "source": [
    "# Conversión de Pandas a tensores de PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d12d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d4acc2",
   "metadata": {},
   "source": [
    "Vamos a usar como puente para la conversión la librería de Numpy. Procedemos a convertir los datos a arreglos de numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66259efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_np=np.array(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9043520f",
   "metadata": {},
   "source": [
    "Así, ya podemos convertir directamente a un tensor de PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49775750",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pt=torch.from_numpy(df_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f7849",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42c99c4",
   "metadata": {},
   "source": [
    "Hacemos lo mismo para el test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12369df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_np=np.array(df_test)\n",
    "df_test_pt=torch.from_numpy(df_test_np)\n",
    "df_test_pt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5895ef6",
   "metadata": {},
   "source": [
    "Normalizamos nuestros datos con Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliza(tensor):\n",
    "    return (tensor-torch.mean(tensor))/torch.std(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf21af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_norm=normaliza(df_train_pt)\n",
    "df_test_norm=normaliza(df_test_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94319e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8dea65",
   "metadata": {},
   "source": [
    "## Construcción del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc5338",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df_train_norm[:,:-1]\n",
    "train_y = df_train_norm[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb5569",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = df_test_norm[:,:-1]\n",
    "test_y = df_test_norm[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a36bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf9e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "dataset=[(i,j) for i, j in zip(train_x, train_y)]\n",
    "testset=[(i,j) for i, j in zip(test_x, test_y)]\n",
    "validation_portion = 0.1\n",
    "int_separa=int(train_x.shape[0]*(1-validation_portion))\n",
    "train_set, val_set = random_split(dataset, [int_separa, train_x.shape[0]-int_separa])\n",
    "len(train_set), len(val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a9bc7",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Generating a full-connected feedforward (FFF) artificial neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f785f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "class Network(object):\n",
    "    \n",
    "    def  __init__ (self,sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        print(\"It has\", self.num_layers, \"layers,\")\n",
    "        self.sizes = sizes\n",
    "        print(\"with the following number of nodes per layer\",self.sizes)\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "    def feedforward(self, x_of_sample):\n",
    "        \"\"\"Return the output of the network F(x_of_sample) \"\"\"        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            x_of_sample = sigmoid(np.dot(w, x_of_sample)+b)\n",
    "        return x_of_sample\n",
    "    \n",
    "    def graph(self,sizes):\n",
    "        a=[]\n",
    "        ps={}\n",
    "        Q = nx.Graph()\n",
    "        for i in range(len(sizes)):\n",
    "            Qi=nx.Graph()    \n",
    "            n=sizes[i]\n",
    "            nodos=np.arange(n)\n",
    "            Qi.add_nodes_from(nodos)\n",
    "            l_i=Qi.nodes\n",
    "            Q = nx.union(Q, Qi, rename = (None, 'Q%i-'%i))\n",
    "            if len(l_i)==1:\n",
    "                ps['Q%i-0'%i]=[i/(len(sizes)), 1/2]\n",
    "            else:\n",
    "                for j in range(len(l_i)+1):\n",
    "                    ps['Q%i-%i'%(i,j)]=[i/(len(sizes)),(1/(len(l_i)*len(l_i)))+(j/(len(l_i)))]\n",
    "            a.insert(i,Qi)\n",
    "        for i in range(len(a)-1):\n",
    "            for j in range(len(a[i])):\n",
    "                for k in range(len(a[i+1])):\n",
    "                    Q.add_edge('Q%i-%i' %(i,j),'Q%i-%i' %(i+1,k))\n",
    "        nx.draw(Q, pos = ps)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d3deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = train_x.shape[1] \n",
    "n_h = 4\n",
    "n_y = train_y.shape[1]\n",
    "    \n",
    "layers = [n_x, n_h, n_y]\n",
    "net = Network(layers)\n",
    "net.graph(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465a7f5c",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "    \n",
    "Architecture definition. \n",
    "    \n",
    "It includes weights and biases initialization, as well as the activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c95c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class architecture(nn.Module):\n",
    "    def __init__(self, n_x, n_h, n_y):\n",
    "        super().__init__()\n",
    "        self.input_nodes=n_x    #input layer has n_x nodes\n",
    "        self.hlayer1_nodes=n_h  #first hidden layer has n_h nodes\n",
    "        self.output_nodes=n_y   #output layer has n_y node\n",
    "\n",
    "        #For the first hidden layer, it is necessary to indicate its input layer, which corresponds to \n",
    "        #the input layer of the network\n",
    "\n",
    "        self.fc1=nn.Linear(self.input_nodes, self.hlayer1_nodes)\n",
    "        nn.init.uniform_(self.fc1.weight)\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "\n",
    "        self.out=nn.Linear(self.hlayer1_nodes, self.output_nodes)\n",
    "        nn.init.uniform_(self.out.weight)\n",
    "        nn.init.zeros_(self.out.bias)\n",
    "\n",
    "    def forward(self, t):\n",
    "        t=torch.tanh(self.fc1(t.float()))\n",
    "        t=self.out(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb9f9be",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Constructing the neural network model for the Learning System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb105b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a model using the architecture defined for the neural network\n",
    "model = architecture(n_x, n_h, n_y).to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b068064a",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Graph and summary of the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e6ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai.plot_model(model, to_file='model.png', show_shapes=True, \n",
    "       show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aebec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai.summary(architecture, n_x, n_h, n_y, 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b410d0",
   "metadata": {},
   "source": [
    "<font size=5  color='blue'>\n",
    "    \n",
    "Compiling the model. It includes the definition of the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eed18bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the optimizing function and their hyperparameters: learining rate(lr) in the present case\n",
    "\n",
    "sgd=optim.SGD(model.parameters(), lr=0.01)\n",
    "compile_step=ai.model_compile(optimizer=sgd, loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba5c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsets={\n",
    "    'normal': train_set\n",
    "}\n",
    "valsets={\n",
    "    'normal': val_set\n",
    "}\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr=[.01],       #[0.1, 0.01, 0.001]\n",
    "    batch_size=[32], #[16,32,64]\n",
    "    num_workers=[1], #[0,1,2,4,8]\n",
    "    device=['cpu'], #['cuda', 'cpu']\n",
    "    trainset=['normal']\n",
    ")\n",
    "\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "history, network=ai.fit(params, num_epochs, model, compile_step, trainsets, valsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bb92a6",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Plots of the cost functions versus epoch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a5a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_loss=[results['loss'] for results in history.run_data]\n",
    "list_val_loss=[results['val_loss'] for results in history.run_data]\n",
    "plt.plot(list_loss, 'magenta')\n",
    "plt.plot(list_val_loss, 'blue')\n",
    "plt.title('Cost function')\n",
    "plt.ylabel('Cost', size=16)\n",
    "plt.xlabel('Epoch', size=16)\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3a38e",
   "metadata": {},
   "source": [
    "<font size=5, color=blue>\n",
    "Evaluation of the learning. This is done using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd5c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = OrderedDict(\n",
    "    batch_size=[test_x.shape[0]],\n",
    "    num_workers=[2], #[0,1,2,4,8]\n",
    "    device=['cpu'], #['cuda', 'cpu']\n",
    ")\n",
    "\n",
    "evaluations=ai.evaluate(network, testset, params, valsets, compile_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed99f6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9de0cb8979005a9fff42dde39678d4f256436e8b7f6ac6d93e23729d89a5cc76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
