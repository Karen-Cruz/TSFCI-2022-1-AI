{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='blue'>\n",
    "\n",
    "# <center>Class 9, November 17, 2021</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-22T12:50:36.354304Z",
     "start_time": "2020-11-22T12:50:36.345388Z"
    }
   },
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/1024px-Regularization.svg.png\" width=300 height=300 align = \"left\" > \n",
    " <img src=\"./images/Loss-function-no-dropout.png\" width=420 height=420 align = \"center\" >    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T00:57:23.623361Z",
     "start_time": "2020-11-25T00:57:23.618614Z"
    }
   },
   "source": [
    "<img src=\"./images/Loss-function-dropout.png\" width=420 height=420 align = \"center\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Cross validation: Identification of overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "\n",
    "During training, part of the data, not used for training, test the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Regularization as a method to reduce overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "\n",
    "When an artificial intelligence model (for example one based on neural networks) has many irrelevant features, the model presents overfitting, which is corrected by regularization, so that only a few features that are highly predictive of the outcome have large non-zero weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "L1 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T13:12:56.281916Z",
     "start_time": "2020-03-30T13:12:56.277895Z"
    }
   },
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "[L1 regularization](./literature/Statistical_Debugging_of_Sampled_Programs.pdf)\n",
    "    \n",
    "<font size=5 color='black'>    \n",
    "$$   J = Error(y, F(x)) $$\n",
    "\n",
    "<font size=4 color='black'>    \n",
    "L1 regularization uses a penalty term which encourages the sum of the absolute values of the parameters (weights) to be small:\n",
    "        \n",
    "<font size=5 color='black'>\n",
    "$$   J = Error(y, F(x)) + \\lambda \\sum_{i = 1 }^{N} | w_i | $$\n",
    "  \n",
    "<font size=4 color='black'>\n",
    "\n",
    "In many learning systems, it has frequently been observed that L1 regularization causes many parameters to equal zero, so that the parameter vector is sparse. $\\lambda$ is the regularization parameter.\n",
    "    \n",
    "$$ $$\n",
    "[More about L1 regularization](./literature/lasso.pdf)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T13:12:56.281916Z",
     "start_time": "2020-03-30T13:12:56.277895Z"
    }
   },
   "source": [
    "<font size=4 color=\"black\">\n",
    "\n",
    "[L2 regularization](./literature/L2_1999.pdf)\n",
    "    \n",
    "<font size=5 color='black'>    \n",
    "$$   J = Error(y, F(x)) $$\n",
    "\n",
    "<font size=4 color='black'> \n",
    "L2 regularization, encourages the sum of the squares of the parameters (weights) to be small:\n",
    "$$ $$\n",
    "    \n",
    "<font size=5 color='black'>     \n",
    "$$   J = Error(y, F(x)) + \\lambda \\sum_{i = 1 }^{N}  w_i{^2}  $$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "\n",
    "[L1 versus L2 regularization](./literature/Regularization_Ng_2004.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "Dropout   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "[Dropout](./literature/dropout_2014.pdf)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:39:59.411767Z",
     "start_time": "2020-03-30T19:39:59.406252Z"
    }
   },
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "This method prevents overfitting and provides a way of approximately combining exponentially many different neural network architectures efficiently. The term “dropout” refers to dropping out units (hidden and visible) in a neural network.\n",
    "    \n",
    "<img src=\"./images/dropout_image.jpeg\" width=600 height=600 align = \"midle\" >     \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "More regularization methods\n",
    "    \n",
    "<font size=4 color=\"black\">\n",
    "    \n",
    "[Example: early stopping](./literature/early_stopping_1998.pdf)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/Picture1.png\" width=420 height=420 align = \"center\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Object Recognition through images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/cifar-10.png\" width=420 height=420 align = \"center\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<img src=\"./images/cifar-10.png\" width=420 height=420 align = \"left\" >\n",
    "<img src=\"./images/cifar-10-classes.png\" width=420 height=420 align = \"right\" >\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "CIFAR-10 database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "\n",
    "[80 million tiny images from internet](./literature/80millionImages.pdf)\n",
    "\n",
    "The CIFAR-10 and CIFAR-100 are labeled subsets of a 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font size=4 color='black'>   \n",
    "\n",
    "The data base can be downloaded from the following URL: \n",
    "    \n",
    "[CIFAR-10 data download](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "$$ $$\n",
    " The CIFAR-10 dataset consists of 60,000 32x32 colour images in 10 classes, with 6000 images per class. There are 50.000 training images and 10,000 test images.\n",
    "\n",
    "The ten classes are:\n",
    "\n",
    " \n",
    "| index | class name |\n",
    "| --- | --- |\n",
    "| 0 | airplane |\n",
    "| 1 | automobile | \t\t\t\t\t\t\t\t\t\t\n",
    "| 2 | bird |\t\t\t\t\t\t\t\t\t\t\n",
    "| 3 | cat |\t\t\t\t\t\t\t\t\t\t\n",
    "| 4 | deer |\t\t\t\t\t\t\t\t\t\t\n",
    "| 5 | dog |\t\t\t\t\t\t\t\t\t\t\n",
    "| 6 | frog |\t\t\t\t\t\t\t\t\t\t\n",
    "| 7 | horse |\t\t\t\t\t\t\t\t\t\t\n",
    "| 8 | ship |\t\t\t\t\t\t\t\t\t\t\n",
    "| 9 | truck|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:26.481916Z",
     "start_time": "2021-01-28T12:05:20.162516Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5 color=\"blue\">\n",
    "\n",
    "CIFAR-10 data is also available from Keras: \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 4 color=\"black\">\n",
    "\n",
    "[CIFAR-10 Keras](https://keras.io/api/datasets/cifar10/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:26.487369Z",
     "start_time": "2021-01-28T12:05:26.484179Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:28.041050Z",
     "start_time": "2021-01-28T12:05:26.489960Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:28.048964Z",
     "start_time": "2021-01-28T12:05:28.042822Z"
    }
   },
   "outputs": [],
   "source": [
    "print('The type of x_train is', type(x_train))\n",
    "print('The type of y_train is', type(y_train))\n",
    "\n",
    "print('\\nThe type of x_test is', type(x_test))\n",
    "print('The type of y_test is', type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:28.097981Z",
     "start_time": "2021-01-28T12:05:28.050333Z"
    }
   },
   "outputs": [],
   "source": [
    "print('The shape of x_train is', x_train.shape)\n",
    "print('The shape of y_train is', y_train.shape)\n",
    "\n",
    "print('\\nThe shape of x_test is', x_test.shape)\n",
    "print('The shape of y_test is', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Analyzing the data extracted from CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T20:18:56.606700Z",
     "start_time": "2020-03-24T20:18:56.598151Z"
    }
   },
   "source": [
    "<font size=5 color=\"blue\">\n",
    "    \n",
    "View a sample from the data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "The input for a sample of the data sets is an array, where each value is the value of a single pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:28.182847Z",
     "start_time": "2021-01-28T12:05:28.099943Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = 0\n",
    "print(\"The features of a training sample \\n \\n\", x_train[sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "Each value of the variable X in the example is between 0 and 255, they are not normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:28.274965Z",
     "start_time": "2021-01-28T12:05:28.187875Z"
    }
   },
   "outputs": [],
   "source": [
    "# We define a dictionary to associate the class number to a class name.\n",
    "\n",
    "dic = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', \n",
    "       5: 'dog', 6: 'frog', 7:'horse', 8: 'ship', 9: 'truck'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "    \n",
    "Showing the image and label (variable Y) of any sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:28.770488Z",
     "start_time": "2021-01-28T12:05:28.282045Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(x_train[sample]);\n",
    "\n",
    "print(\"\\nThe y value of the first training sample is\",np.squeeze(y_train[sample]))\n",
    "print(\"It correspons to a\", dic[int(np.squeeze(y_train[sample]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Features (X values) normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size=4 color=\"black\">\n",
    "To normalize x values, we divide them by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:29.497371Z",
     "start_time": "2021-01-28T12:05:28.772455Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x = x_train/255\n",
    "test_x = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">    \n",
    "\n",
    "Now the pixel values are between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:29.506208Z",
     "start_time": "2021-01-28T12:05:29.498725Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:29.663886Z",
     "start_time": "2021-01-28T12:05:29.508215Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_x[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:29.669831Z",
     "start_time": "2021-01-28T12:05:29.666030Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "One-hot encoding of target variable (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "The target value can have one of ten elements (classes), the digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9). \n",
    "\n",
    "The sets train_y and test_y are arrays in which each entry contains a digit represented as a integer of 64 bits.\n",
    "    \n",
    "We change this representation to a vector following the One-hot encoding \n",
    "[One-hot encoding](https://en.wikipedia.org/wiki/One-hot).\n",
    "    \n",
    "In One-Hot encoding, a digit is represented with a vector that has dimension 10 (because we have 10 classes) with 1.0 in the vector index corresponding to the digit and 0.0 elsewhere in the vector. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:29.688134Z",
     "start_time": "2021-01-28T12:05:29.671816Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:29.703632Z",
     "start_time": "2021-01-28T12:05:29.689533Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:29.719303Z",
     "start_time": "2021-01-28T12:05:29.704733Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y = np.eye(10)[y_train.reshape(-1)]\n",
    "test_y = np.eye(10)[y_test.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:29.728703Z",
     "start_time": "2021-01-28T12:05:29.720711Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:29.745906Z",
     "start_time": "2021-01-28T12:05:29.730644Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T17:58:01.255256Z",
     "start_time": "2020-11-23T17:58:01.245993Z"
    }
   },
   "source": [
    "<font size=5 color=\"blue\">\n",
    "    \n",
    "Viewing one sample from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:29.874059Z",
     "start_time": "2021-01-28T12:05:29.748017Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = 9\n",
    "\n",
    "plt.imshow(train_x[sample]);\n",
    "\n",
    "print('The sample', sample, 'corresponds to a', dic[int(np.argmax(train_y[sample]))])\n",
    "print(\"Its one-hot representation is =\", train_y[sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "In summary, the training and test sample sets have the following dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:29.881332Z",
     "start_time": "2021-01-28T12:05:29.876125Z"
    }
   },
   "outputs": [],
   "source": [
    "print (\"number of training examples = \" + str(train_x.shape[0]))\n",
    "print (\"number of test examples = \" + str(test_x.shape[0]))\n",
    "print (\"X_train shape: \" + str(train_x.shape))\n",
    "print (\"Y_train shape: \" + str(train_y.shape))\n",
    "print (\"X_test shape: \" + str(test_x.shape))\n",
    "print (\"Y_test shape: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Building the Learning System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T18:05:49.800018Z",
     "start_time": "2020-11-23T18:05:49.790932Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "\n",
    "Definition of the neural network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='black'> \n",
    "    \n",
    "Keras has two different modes to define the architecture:\n",
    "\n",
    "<font size=4 color='black'> \n",
    "    \n",
    "1.- The sequential model. It is a sequential stack of layers.\n",
    "    \n",
    "2.- The functional API. It is the way to go for defining complex models, such as multi-output models, directed acyclic graphs, or models with shared layers.  \n",
    "\n",
    "In the present case, we will use the latter mode to build the network architecture.\n",
    "    \n",
    "Documentation: [Keras Functional API](https://keras.io/getting-started/functional-api-guide/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:29.913738Z",
     "start_time": "2021-01-28T12:05:29.882833Z"
    }
   },
   "outputs": [],
   "source": [
    "def architecture(input_shape, num_classes, dropout=False):\n",
    "    \n",
    "    # Defining the input as a tensor with shape input_shape. \n",
    "    InputLayer = Input(input_shape)\n",
    "    \n",
    "    # Flattening the input tensor of dimensions (32, 32, 3) to a tensor of dimensions (3072)\n",
    "    x = Flatten()(InputLayer)\n",
    "    if dropout == True:\n",
    "        x = Dropout(0.0)(x)\n",
    "    \n",
    "    # Defining the first hidden layer with 50 nodes and sigmoid as activation function\n",
    "    x = Dense(50, kernel_initializer='random_uniform', bias_initializer='zeros', name='hl_1')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    if dropout == True:\n",
    "        x = Dropout(0.0)(x)\n",
    "\n",
    "    # Defining the second hidden layer with 50 nodes and sigmoid as activation function\n",
    "    x = Dense(50, kernel_initializer='random_uniform', bias_initializer='zeros', name='hl_2')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    if dropout == True:\n",
    "        x = Dropout(0.0)(x)\n",
    "    \n",
    "    \n",
    "    # For the output layer we use the activation function 'softmax')\n",
    "    x = Dense(num_classes, kernel_initializer='random_uniform', bias_initializer='zeros')(x)\n",
    "    OutputLayer = Activation('softmax', name='output-layer')(x)\n",
    "    \n",
    "    # This creates the Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = InputLayer, outputs = OutputLayer, name='Cifar10Model')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAA+CAYAAADwFrunAAAABHNCSVQICAgIfAhkiAAAGC1JREFUeF7tnb13HEd2xQV6A5/jcyxQf4DZQyeOlsA6XzToyMkSkPPlgLmX4Dr2ckBHDnYJKrc4kBMnFgA7cWALPcotAgqcWRiscxF0bsn3B1RJxUL1dPd8Y+a9c67q69WrV7deVdf0DKgPPjAxBowBY8AYMAaMAWPAGDAGjAFjwBgwBowBY8AYMAaWhYG2JvpWeC2sCvvLMnGbpzFgDBgDxsBiMHBnMaZhswgYyJXfFs6EU6EbtG0pvxaULWsMGAPGgDFgDBgDxsDUGOCNSXwR6STqpuaQDWQMGAPGgDFgDBgDy8tA6mKyvGzYzI0BY8AYMAaMAWNgKgysaBQQS3wx2ZXCqtARurGylY0BY8AYMAaMgXljIPVwmzcfzZ8fGbirLJeNR8KlwKWjJzx1Kl1Xxw9i+8KW8EzIBS4t1NHHxBgwBowBY8AYMAaMgZEZWJOFN8Kp4C8Y/KC5L6wLmdAWENIjIb8uXv13RzgIypY1BowBY8AYMAaMAWNgaAZ4w8Vf31wK4ZuP+yp/L/BGpUq41HCJ4ZJjYgwYA8aAMWAMzC0DP5lbz8yxkAHeevxU4G2If0vyQPkt4YnA1zhVwqWGi0wmcFExMQaMAWPAGDAG5pIB+83JXC7LDaeOVfMLga9lLgTeoPAm5UTgwlFH2k6pW0fZdIwBY8AYMAaMgTExwBt7fivp7xw8t/ac7VzphsvzfOu6vCW3gIGefGQxW7fAV3PRGDAGjAFjwBgIGchU4E0/z7F9IQ8aubjwgXtXIG9yixjgjQmL6m+doet8zbN6i+ZirhoDxoAxYAwsHwP+csIzywv5rjDRZxgDDyM7w3Rasj4PNV8uJ5vRvCn3hWzJ+LDpGgPGwHQZ4LdtJtNnYNjn6vQ9rR7xlVR4Q+KFZ/9eWTf+FHUc0pWRu0Ma4jXOiyH7Lku3LxxHh0o7Dvze5LHAzbMvLKoQV9tCR2gt6iRtXlcM8GYwhZieUCdum2UZv4jXXJjoJ8EpT/JA492b8pg23DUDPKOPZ0wGcY0fHr7s92Fd9/hdSeGUiakPhed1Ow+jx20IDCtM8Eywm3k1gy2pbAoPBQ7BRZd1TZC/ROLyWrj8NOf9TGNuzxHJ7DP2yyIKD3PeDqbABxgvnYTOPKwR6xL6zh5dBPm1JlEswkRu8RzY990Z+s/YfYee0lPhneDzxP2JsCOUid/ffi59KR6VKY+jngclTt4d0Rgbmdc9o9oZ0Q3rPkcMEAvExIHziQ3BJlifko9sNMab6AaqmEtL7fixL5w7f/j0sqiyoolxpsD7hUA5JcRCIWwP0En1m3Qd/nL44v8iXE7Yg3w4uD9p4sz+QAb8WTjLmGJf7jkvSdl7XrjAEvfUF0F9mEWffXEgcFFBl3KrRP/qNc0o8lydcarOv7MxaJwTNZ4JzwYpWdtSMbCm2fLaj2BG2Bwckm9cedIJMfl3wu6kBxpgnzmzeS+EdwP0FqWJwyp3kymUUg4FLnrCJ0Iu8DVnrPNehykX8IUL9aIIl+IvhW8WZUK3dB48Xz8T/lZYGWEOvi8p4PnfxF6oG8b5S9l5IHAfOBY6QiwbquAMeyzQ97VTaMeK4yj/TEbYjBwY45AdGWERRr0wjcMXszF7Bh7KBeKLdNmFQ6FwfCzy/gjn+SRa9E3HwfqcB8OeW6fbHrd33Ty255zvZXGP5yznIc/dpsJadgTeOIJC6DmQZ99VCfH8wikR42F8+33L2UQe27Ew7lFU2VW59MVG3YOOAeMJbKmOm1A/GpAiutj28OWUHd+dCa0Kua+w1BhwDMSx54nx8VTVjv6g2IuJbqIb97XyaAzwCQsJDzJeG+8KPCiHeXNW5/xhzHjd4/KVYwmpqxd3LTsj0SuL6djGpMqbznCvxgCz9rWGixNXGTYG6jrWlyLPW567TYR1ZM/8XiC/JuQC+4wUcOmpEnRCvbgP84/rvE2e67xZOY0GKVSmjb19Q9gcoXDDaguHwkkC1Hv5uTIMlnKIvv8X4DuXJwUH3kiQnisP+RuJNqtaHgYI8lfCb92USYmnJwEFD5VnwxUChyex83HQzgakD6+jibd14Ujglh7aCbr8kPWbGZtVuqn+Vjc8A3CPfC2wVhxcrBtnwiNXR3sT2ZGyj5XC2ehEBtoqEy+sOfGSCV2BfvhBHl9i4VMs/l0IhdAVUnpxP8q5UHZGfq82/GilOk6pjj3Eecz8y8TvM3zddUo8Q07LOixoPXFL7HwrcIFGqOu6/DgSYqIn/LyBMc695wJx+qkQryU268qKFIGXME8dtsAz4fhHtav7BHUvXF3HpcQOoJ6Y8fWu+YMPwv+3Dopd4YFwJrDJ7gnvXJmB/0dAcAz9A1cuS/5GDa8FBv9PAZvIvkvjhHHzuHKIMp+0PmzY71L6Lxv2MfXxM0CcEVcXAjH2j8KpcO6G2lb6ufAXwomA/rrLs+bEW18g6MkjrCsb5CvhNwIbNSX3Vflc2BQOBS5G2GCMQYJtH9uD9MI2Yp15NJUqX5ramyf9DedMTylrD/ecR/0hneScYu2JC9b2XOCg5iziTHoqIIz3TvD7n/OJNUWfOPt3gXgkNrzsKEMcccYRkwg+n7h81TrhG8LYjEU8MP6vrquvfmPA+IOECzn8NJVwHmV9eQjiU9k88P9IgDfmgO+PhEzwfCi78NLSDNnHcMUZQB5eqM+FcQpj+N+dlK1LOJ6PYy5No0ohA5uRkTsqZwJnKv4cC33B7ytlSy9op2rbRaFMMI7cFfymYhOzyTKBoGNQnMoFv3GUvdrwBGZKVlTJ5vqdcCkcCiwcwsXhjcuHCeN4wukfSx5XVJSxkQLdyuorTFrzlBjgEkHwIqRfCOcCccoh+C+uzscL8eTjraU8MUc89wXkEwEdYu+Zq0slbLJXwluBPfB7wY+R0g/rUjE1qK7KXll7am+U6d62+tw5zFmxLzwROGMyYdu1NUlYO2LlTGBNEWKrJ3CWeS6JLc6oiyuN68sxdQixh2y4lIQ45GzDLinjAGKM+EGq4saPzRzptyX48xW7u9dmKv9bFmN0TLVVGgz6DdK9p8aO8EDIhTsCvPAjcr93lb0S1jP3hQVL4WHTzY8z476wLrCul8FcWd+TCL65HdQT92XiY8rHTpke9S2B8Yn3cQjz/C4wRNzz5u+1kAtfC8Ts00BnpKx/c9KRFQKITxXngcUvld8QCEA2kJcqctAvnDKb9acu/5nSlz9YuZl5F+iGrbkKLCyE9292u1EDcZMSguwvJ2V8Cez+l+boD/Cm0+UQYJMQR7G8VQUxvC3E6+9jd1DsYa8nHDobHyo9oLKGVNmtYaK2CvuRvbBowsONT+vI98IjgcOVtf5roS2wNk3ll64DZxbnG+sKBsnRoEa1EWPEGpfeMqk6I5kr5x3nLQ+0f3CGqOPB9rbMcFD/ufJgEoJ/XOzKpK+GrmtkruwV9vXroENbeeIVvvaFImhblGw4p7uaVFfgGXEaTZCYoo71Zn1DnqhvC7tOR0lSqmIq7NRS4Y+FvaSlHyuJM9amSrAXCh/0cuFS4Dx6LjC3sQmXEyb8K4FAjI37TdxvOCKL9L1AUHKwIGfCU4FJ0v7VdfWN/2Y3aq6Dmn79RNu0q/5QA1YdbtP26TaN90c1nf0Tpxfe1h+4OmIrFl/ndcL2i1i5pOwPjEeunQNl3qTJATVvvg/yZ8M18gmsLfj1fKk8Z8gvBM6A+Ixy3UoT+jwXWNMvBR4EnD+xwGsqrkI9r3Mv7pwoV61TR33AqvDPLsUMhz5n40OXcvjPQuruGbj8VPhXwe8f7y9cd4W2r1jgFB4OhUEXjNzNvwh4eKY8cefbgqbSLDHzbWnrjw3EYFUcpvZCynRqb7CvekLXpcTu71Kdh6njcrLpOh5HBpgUG5ogjTdIytGwO+18GiBokXcCt0XsvBIyYYOGSHjoc4CkpJ+qLKn7c9Vza2wizPeLGh3+STrAZLIMtJz5O8EwxBGS2nCpumE8ZLM+Frisf1PTAA+Sqj0Rm2IuZRf0WHcZyrmbZC/i8lxl1oLLCQf/0wZkEENwTGysC9hCOHvuubxP6qyf1/GxNo6Y4zxcc058ppQzE1//Q/iZ8MY7mEhp58xsKic1OlxIh4fgIKH9SHgmpGL5dFDnBWpjvfaFtuBjLDU91hle0YG7PQH+6qwH9nz8XVKoEMbgjPlNhV7d5jjW8QXsCq8F7gqFQyoW6o7zg174g9iY1E1p3RO4DXlSwgH+V4WyjcEBn/o0QP8N4Tg05PJMHvhJU80CsuiZS1nIOsIY9G0iLHidy0kTm6Y7XgYKZ464LJNeoiEVvwm1q6ot13Dg0lOlHD6DbOROt0nSl/JYNrEbNFPKvhv0MEOVi1RVnDPfvvCWDiWSqb5qPPYgtk5KbITV7FmkSOh2Vcfl5JdCRxjkV9h9VwV84IPRedgQ5ImXXGB94wM47uLPJ89x2flHv+/izokyfjEn5GsBfxE4Q85cWpZkalgraxxQj/+cd2UyKNZ9H3jlHMfnMOb2VMb2yzLjiXpsMY8i0RZWbapQ5XvLdShbb5oZD73Q79TQ7BX26CCuWCvmuiW8DYzATUcIx8hVJt4y4VA4EOrsDaldCfGH1Fkf5s88ucCO45yJx/S+YJs4/VjYFpgXaciFisPJfXWDfAx6uavMqQDBZUJbUdL4SvVMBrAATATsuboXiX604wd9vXSVwZcjgb4my8OAj5XNaMrEB4FPXHj5SBk2IzEbSqFCvKkilRvFsA9jH9zQmE2F9yvmA2/83mGuqXbvMXNBJ9xj8Ww4ZNCBY+ymhPp3Tm/QeOzbqvGwz1r684IDNSV9p7OTaiyp45zBbtiHsZgb9cQNqZ9nEZVVvGpDp0chEGLtXAj9JU89+tvvad8srKvK+3GpfEtgLOqxG/p1s/fka+AOPzw38Yh+/vtqaAu50BGYS7g3Vbyayx6ZEoHbKp1nTqcosUE1HGIHkC8TPx42y8R/KD8pU1A9Y7CGcNERWPNcOBIYIxRiA79oeyXQ5837KpWlY2lgd6VS81qBWCqEeD1qdn9PbVOlPVdDStkL/jAfxuFCV/zYNHruiUwQVG2BBSMoIXCQsHip4F1TvQ+QsjR1Obnv+nE4esmUYcLYIW+y+AwQ6IVAbLHupCcCnwAQNjmblHo2CWCT91ybkh8+rfvDn3ZsYLtKiE36bQvYHMfGrhqzrJ05FwK+wwVgLtTtC6Gwf2kftG8Pauj4y0lfumV8Ue/H23zPi/cLR248fE7Z2lJ9IdDu58dc6eeF8yScP3qFsB7olGVZu1OB9dwV2kIhPBOwg91PBM4/6kMf9l09/X09OugiqwJlfN8R2q5MHfqMif3UvFV9NUdvN5VeojRD4SGDX1zgYiHGQEvwMYUuPqfWhba92EhQ9hz3VFfGl18zdMoEfzyX5MsEG+hhs0xYf2/rTonSmep5DjJWGCfkib1QdlTAHiniy2uh0oD8itrgl3htIttSxh/Gw0YocbnMLjwdCoWwJxy5cifosKl8z7WzJ0AWtDfOhs5xOXgkUIcj5xXWODj59wLoF+vi6KCJ4zibN5QdFfi+lc0QtkHMY6HuIr5v9faWVqM5E9hsBgI0E+4FUyMoFkni+GHuxAxz97KuDHofCmwW2r3AHe0IcUh/5MSlVQkPIOy+FsIxq/qNu93PI7WXvtVgp8GAHIa50BYeDXCEh06dr3XY04Pm3lI7/oW8p4ZljV4KrIdfB6+XKcP5EQo67H8/t3gtvW7V63avB3cc0GsCczoUmBfnF7bhIhO8H4xPH3wAzDOMIWz0BS/wiW3qiC/yuVAICHUpyVQZzz3Uw8dxvI5PjV2n7o6UiLEdAc5C4UxmTb08cRn04CwWOH0hPI8bXNmvcUflXEA/JcTSGwFuyoT1QlinMvHjla2N78d4zJNYib+my1THWh85ZWzC1YUAD/EcuqrLhUxA0O8Lx8Lj66qB/2Ve3wh/JXw+UPNmI33bAuP0BXxbCdTyIJ/KEuNlEp4lfk953bp7tMz2SPWFenNzHFUgClsHCUOnqmPRc4FgWBbJNNGOQCAVwm4w8dzVd6P6QMWyS8gAD4lx7MdxUselyR/g47RrtibPABeK1JncdGTOsL2KTvfVzoN6noTn0tmYHOrLTszlvurghotKlbAW/SqlinbmE+KOK1d0u53N3KggjAmPIty4LoVWwgiLx6Wkm2hb9KpcE2T+m8FECWS4WKaL2qKv8zjmxx4shNQeGof9YW3sqePOsJ2t30wZ4MLA+UM6jHBGbTgbr5XmQtmD+EBtvOGaJ+H5hl+jCBw8EuARDvy5DQ/PE/Wpsbjg80YqfA6k9KwuYoDF4wAaVlbUsSfwqjAlW6rsCGVBneqzKHVwQlDDEbIuwPcycuEosKSEAfYgn67mSThMT+fJIfOlMQNP1GPYNxqc3blAHADKmRALl5Jhx4htjavckqG+MOpZuyYbfv5t5eEAyVw+5MY13UheqWbe+Lnh5LxW9OQYt8xhhAP1YJiOc9JnRX4AxOebpmVTOVJD4Rq5qOyXKVr90jOQzSEDHOyjHu5zOK2lc4mHI+fPpGRe4ySb1IQb2P1YuqeC7aMGpIWqEMftdxjZHabTHPThAnIp8GZjFPC6zl9u4mlhf9+BfDdWsLIxYAwYA1NgYN5+yzSFKc/FEG15YReTuViK2+XEJ3KXi8m58JFQ9saEWfk23jDxqrQQ/KWG23Es664dvUzYc+VWrDjDcq6x/cZZm6EfNrQxYAwYA8aAMWAMOAa4cJwKXDKOGrJCXy4qvBFJ9d11dr3ZzJW5pMyD4DPz5k/7HgudeXDKfDAGjAFjwBgwBoyB67+B54LBg3qY72V5Q0L/uxGZPPyLqK6rMm9pZi2rcmDLOZEp7SYcon0/UW9VxoAxYAwYA8aAMTAFBviaxn9Fw59FNxV+FLwTdcJeJ6rjgU99O6qfVXFNA+8KXFZioQ2YGAPGgDFgDBgDxsCMGDjWuP5rjtTDuq5bPOyLAPuuY1ZSX9fuuPW4ePAr/pQwf7uYpJixOmPAGDAGjAFjYIoM8LXMhcAFpTvFcSc1FL+J4Ye6HaEthBcuLh5HwcB8NeW/0qINfdrtghKQZFljwBgwBowBY2AWDPCVjv96Z3sWDoxpTC4l/LblQNgU+BHuqbPNJYWLR0e4FPhBLG3UI22XFkrpa2IMGAPGgDFgDBgDM2aA349wQeHfL7k/Y1+GGd7/fobUC29RuIjwdigT/EWE/JZXilI4MDEGjAFjwBgwBoyBOWCAB3lP8L8/oXxbhMsUfheBw/jPVzZnDSbBG5PQRoOupmoMGAPGgDGw7AzcWXYCJjB/Hu68TXgnrAmPJzDGpEw+dYbvKT0RCoGvbTJhw7XVSXIpFXUUTccYMAaMAWPAGDAGpsfAKw1VTG+4kUcK3/jw2xkurtQN8+aHeecje2QGjAFjwBgwBowBY2BsDPBw50ei/EZjVNmXgaMhjGTqkwudBv0L6fLmZ5g3apnry9si5m5iDBgDxoAxYAwMxcAwD6GhBlqiTvxu41Dgr3X4UeyowoO+M4SRTH1ygXS1Zv8Lp8cFJRZ+d5LFlUG5rzw6ucAFxcQYMAaMAWPAGDAG5oAB3pTwG41h/pXYSbnfkeGipnEuVlxMfh3ot5TnsvVZTRumZgwYA8aAMWAMGANzwoD/zcaTIfzhzcafRv1ylflKB4wiHXUuGhjgYoU+f53TE46Fhw36m6oxYAwYA8aAMTASAz8Zqbd1DhnoqsDD/NMhaKEvbyb+2/VdV8pXI7sCbzKOhEvhpWsflOypsRikUNH2ldpzgcsWkvqKxzVZYgwYA8aAMWAMGAPzygBvSw6GdI6+XDz8ZQAzXEoQLihcDkb5YW1H/YsraybGgDFgDBgDxoAxsBQM8E+98xVI0wvER+rDVzZcPsouNvzA9HREFjvqX4xow7obA8aAMWAMGANTY8C+1hmNar5++a3AJYK3HCnh8sFbkVWnQzkXNgJlfteREnQK15Ap3UkpRXUnQZ8a6qZiDBgDxoAxYAwYA4vEQF+T4bIxCuKvdEJ+aNsekbCO+hcj2rDuxoAxYAwYA8bA1BgIf+cwtUEXbKBxcMjlJhbeyvDjVL4u4pLSVHiTw9dGofAV0W5TQ6ZvDBgDxoAxYAwYA8vNQOamzyWCy4SJMWAMGAPGgDFgDBgDM2Mg18i8ReGtx7mwNTNPbGBjwBgwBowBY2BGDPzBjMa1YcsZ4GucPxP+Xvi3cjVrMQaMAWPAGDAGjAFjwBgwBowBY8AYMAaMAWPAGDAGjAFjwBgwBoyB5WLg/wExz8dmqw/eXwAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>    \n",
    "The softmax activation function is always used for classification when the number (K) of classes is greater than two: \n",
    "\n",
    "![image.png](attachment:image.png)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T18:29:47.071906Z",
     "start_time": "2020-03-24T18:29:47.067719Z"
    }
   },
   "source": [
    "<font size=5 color=\"blue\">\n",
    "\n",
    "Building the neural network model for the learning system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:30.049214Z",
     "start_time": "2021-01-28T12:05:29.918228Z"
    }
   },
   "outputs": [],
   "source": [
    "one_image = (32, 32, 3)\n",
    "num_classes=10\n",
    "dropout=True\n",
    "\n",
    "cifar10_model = architecture(one_image,num_classes,dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T00:03:50.539765Z",
     "start_time": "2020-03-24T00:03:50.534266Z"
    }
   },
   "source": [
    "<font size=5 color=\"blue\">\n",
    "    \n",
    "Graph of the model and summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'> \n",
    "The 'plot_model()' function generates a graphic with the layers and their number of input ands output weights.\n",
    "$$ $$\n",
    "Documentation: [Model visualization](https://keras.io/visualization/#training-history-visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:30.332866Z",
     "start_time": "2021-01-28T12:05:30.050947Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(cifar10_model, to_file='cifar10_blocks.png', show_shapes=False, rankdir='LR',show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:30.484527Z",
     "start_time": "2021-01-28T12:05:30.336445Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(cifar10_model, to_file='cifar10_model.png', show_shapes=True, rankdir='TB', show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:30.493424Z",
     "start_time": "2021-01-28T12:05:30.487401Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "cifar10_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Optimization method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 color=\"black\">\n",
    "This requires defining the optimization algorithm, loss function and metric.\n",
    "    \n",
    "In the present case we are using the Stochastic Gradient descent algorithm with learning rate \"lr\", \"momentum\",  and without Nesterov acceleration\".\n",
    "\n",
    "\n",
    "[An overview of gradient descent optimization algorithms](./literature/SGD_overview_2016-17.pdf)\n",
    "\n",
    "This post also comments on some other optimization variants of this algorithm; Adagrad, Adadelta, RMStrop and Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-24T00:09:25.688121Z",
     "start_time": "2020-11-24T00:09:25.680769Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "Mini-batch stocastic gradient descent(SGD) method.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'> \n",
    "The training samples are divided into mini-batches that have the size batch_size (B). Updates of weights and biases are based on an average of the gradient within each block of B samples. \n",
    "    \n",
    "$$ \\omega^{(t)} := \\omega^{(t-1)} - \\alpha \\dfrac{1}{B} \\sum_{t^1=Bt +1}^{B(t+1)}\\dfrac{\\partial J(x^{(t^1)},y^{(t^1)},\\omega, b)}{\\partial \\omega}$$\n",
    "\n",
    "$$ b^{(t)} := b^{(t-1)} - \\alpha \\dfrac{1}{B} \\sum_{t^1=Bt +1}^{B(t+1)}\\dfrac{\\partial J(x^{(t^1)},y^{(t^1)},\\omega, b)}{\\partial b}$$\n",
    "\n",
    "$ \\alpha $ represents the learning rate and *t* represents an iteration. \n",
    "    \n",
    "This method is specially useful for large sets of training data.\n",
    "    \n",
    "[Gradient-Based Training](./literature/Practical_rec_DL_Bengio_2012.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:30.525013Z",
     "start_time": "2021-01-28T12:05:30.494609Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "The cost (loss) and Metric functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "The cost function *J* is defined as \"categorical_crossentropy\"\n",
    "    \n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\sum_{k=0}^{K-1}(y_k^{(i)}*\\log{(F_k(x^{(i)})))}$$\n",
    "    \n",
    " where $F_k(x^{(i)})$ is the predicted value and $y_k^{(i)}$ is the target value for the sample *i*; *K* is the number of classes and *m* is the number of samples.\n",
    "    \n",
    "[Cross entropy](https://en.wikipedia.org/wiki/Cross_entropy)\n",
    "    \n",
    "[Categorical cross entropy](https://www.deeplearningbook.org/)\n",
    "    \n",
    "\n",
    "A metric function is similar to a loss function, except that the results from evaluating a metric are not used when training the model. You may use any of the loss functions as a metric function. In the present example, we are using \"accuracy\" as metrics:\n",
    "    \n",
    "*Accuracy = Number of correct predictions / Total number of predictions made*\n",
    "    \n",
    "\n",
    "Categorical crossentropy will compare the distribution of the predictions (the activations in the output layer, one for each class) with the true distribution, where the probability of the true class is set to 1, and 0 for the other classes.\n",
    "\n",
    "To put it in a different way, the true class is represented as an encoded vector, and the closer the model’s outputs are to that vector, the lower the loss.\n",
    "    \n",
    "Documentation: [keras.compile(...)](https://keras.io/models/model/#compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:30.528828Z",
     "start_time": "2021-01-28T12:05:30.526265Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_function = 'categorical_crossentropy'\n",
    "metric_function = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T19:12:50.153175Z",
     "start_time": "2020-11-23T19:12:50.148215Z"
    }
   },
   "source": [
    "<font size=5 color='blue'>\n",
    "Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T12:05:30.608061Z",
     "start_time": "2021-01-28T12:05:30.530475Z"
    }
   },
   "outputs": [],
   "source": [
    "cifar10_model.compile(optimizer = optimizer, loss = loss_function, metrics = [metric_function])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "    \n",
    "Training the learning system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color='blue'>\n",
    "    \n",
    "Shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T21:49:35.336666Z",
     "start_time": "2020-11-23T21:49:35.331145Z"
    }
   },
   "source": [
    "<font size=4 color='black'>\n",
    "\n",
    "Shuffling the training data before each epoch has a large effect on the loss associated with the test samples. Shuffling the training data, the samples for each mini-batch change with the epoch.\n",
    "    \n",
    "To speed up the convergence of weights and biases, it is also possible to fix the samples associated with each mini-batch. Then, the mini-batches will be called randomly in each epoch.  \n",
    "    \n",
    "[An overview of gradient descent optimization algorithms](./literature/SGD_overview_2016-17.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\">\n",
    "    \n",
    "Documentation: [keras.fit(...)](https://keras.io/models/model/#fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-28T12:05:20.282Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#10 % of the training data will be used to validate the training\n",
    "validation_portion = 0.1\n",
    "num_epochs = 100\n",
    "\n",
    "history = cifar10_model.fit(x = train_x, y = train_y, epochs = num_epochs, batch_size = 32, \\\n",
    "                            validation_split = validation_portion, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "Graph of cost functions as a function of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-28T12:05:20.286Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Lr = 0.01, Dropout: Inp = 0.0, hl_1 = 0.0, hl_2 = 0.0')\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"blue\">\n",
    "Graph of accuracy functions as a function of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-28T12:05:20.289Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Lr = 0.01, Dropout: Inp = 0.0, hl1 = 0.15, hl2 = 0.0')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5 color='blue'>\n",
    "Loss and accuracy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size= 4 color='black'>    \n",
    "After training the network, the loss and accuracy functions are evaluated using the test samples (test_x, test_y).    \n",
    "\n",
    "    \n",
    "[Method evaluate in Keras](https://keras.io/models/model/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-28T12:05:20.293Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluations = cifar10_model.evaluate(x = test_x, y = test_y)\n",
    "\n",
    "print (\"Loss = \" + str(evaluations[0]))\n",
    "print (\"Test Accuracy = \" + str(evaluations[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-28T12:05:20.295Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation using the first 100 samples of the test set\n",
    "\n",
    "evaluations = cifar10_model.evaluate(x = test_x[:100], y = test_y[:100])\n",
    "\n",
    "print (\"Loss = \" + str(evaluations[0]))\n",
    "print (\"Test Accuracy = \" + str(evaluations[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5 color='blue'>\n",
    "Image prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size= 4 color='black'>    \n",
    "The trained learning system can predict the object content of an image. For example, we take an image of the test dataset (test_x, test_y). \n",
    "    \n",
    "[Method predict in Keras](https://keras.io/models/model/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-28T12:05:20.299Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicting the image associated to the each sample in the test set (X_test)\n",
    "predictions = cifar10_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-28T12:05:20.301Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = 31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"black\"> \n",
    "Displaying the image associated (not predicted!) to this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-28T12:05:20.305Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(test_x[sample].reshape((32, 32, 3)))\n",
    "\n",
    "print('the sample', sample, 'corresponds to a', dic[int(np.argmax(test_y[sample]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-28T12:05:20.309Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicting the image associated to the sample \n",
    "# np.argmax returns the index of the maximum value\n",
    "\n",
    "prediction = np.argmax(predictions[sample])\n",
    "\n",
    "print('For the sample number', sample, 'the prediction is a(n)', dic[prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 4 color=\"black\">\n",
    "    \n",
    "The next function finds the number of samples where the network made an incorrect prediction in a region of the test dataset. For example, in the first 40 samples from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-28T12:05:20.313Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "mislabeled_images = []\n",
    "\n",
    "for i in range(len(test_x[:40])):\n",
    "    \n",
    "    if np.argmax(cifar10_model.predict(test_x)[i]) != np.argmax(test_y[i]):\n",
    "        \n",
    "        mislabeled_images.append(i)\n",
    " \n",
    "\n",
    "\n",
    "mislabeled_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "Keras has the several options to use regularizers L1, L2 or both simultaneously. \n",
    "It also has the option of creating custom regulirizers.\n",
    "    \n",
    "[Keras layer weight regularizers](https://keras.io/api/layers/regularizers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color='black'>\n",
    "    \n",
    "[Runs summary](clase9-figures.odt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
